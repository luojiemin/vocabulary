import streamlit as st
st.set_page_config(page_title="è‹±è¯­è¯æ±‡æ‰©å±•ç³»ç»Ÿ", layout="centered")

import pandas as pd
import easyocr
from PIL import Image
import numpy as np
import io
from docx import Document

@st.cache_resource
def load_reader():
    return easyocr.Reader(['en', 'ch_sim'])

reader = load_reader()

st.title("ğŸ“˜ é«˜ä¸‰å¸¸å¿˜è‹±è¯­è¯æ±‡æ‰©å±•å­¦ä¹ ç³»ç»Ÿ")

uploaded_files = st.file_uploader("ä¸Šä¼ ä¸­è‹±æ–‡æˆªå›¾ï¼ˆæ”¯æŒå¤šå¼ ï¼‰", type=["png", "jpg", "jpeg"], accept_multiple_files=True)

results = []

def enrich_word_data(word, meaning):
    sample_dict = {
        "violate": {
            "pos": "v.",
            "collocation": "violate the lawï¼ˆè¿æ³•ï¼‰",
            "example": "He was fined for violating traffic rules.ï¼ˆä»–å› è¿åäº¤é€šè§„åˆ™è¢«ç½šæ¬¾ã€‚ï¼‰",
            "derivatives": "violates, violating, violated, violation (n.), violator (n.)",
            "confusing": "violetï¼ˆç´«ç½—å…°ï¼‰, violentï¼ˆæš´åŠ›çš„ï¼‰"
        }
    }
    data = sample_dict.get(word.lower(), {})
    return {
        "word": word,
        "pos": data.get("pos", ""),
        "cn_meaning": meaning,
        "collocation": data.get("collocation", ""),
        "example": data.get("example", ""),
        "derivatives": data.get("derivatives", ""),
        "confusing": data.get("confusing", "")
    }

def is_chinese(text):
    return any('\u4e00' <= ch <= '\u9fff' for ch in text)

if uploaded_files:
    with st.spinner("æ­£åœ¨è¯†åˆ«å›¾åƒå¹¶æå–è¯æ±‡ï¼Œè¯·ç¨å€™..."):
        for file in uploaded_files:
            image = Image.open(file)
            result = reader.readtext(np.array(image))
            lines = [line[1] for line in result]
            st.text(f"DEBUG: å…±è¯†åˆ«åˆ° {len(lines)} è¡Œæ–‡å­—")
            st.write(lines)  # è°ƒè¯•æ˜¾ç¤ºæ‰€æœ‰æ–‡æœ¬

            for i in range(len(lines) - 1):
                if lines[i].isalpha() and is_chinese(lines[i + 1]):
                    word = lines[i]
                    meaning = lines[i + 1]
                    result_data = enrich_word_data(word, meaning)
                    results.append(result_data)

if not results and not uploaded_files:
    results = [enrich_word_data("violate", "è¿å")]

if results:
    df = pd.DataFrame(results)
    st.success(f"å…±æå–åˆ° {len(results)} ä¸ªè¯æ±‡")
    st.dataframe(df)

    doc = Document()
    doc.add_heading("é«˜ä¸‰è‹±è¯­å¸¸å¿˜è¯æ‰©å±•è®°å¿†æ‰‹å†Œ", level=1)
    for item in results:
        doc.add_paragraph(f"â–  {item['word']}  {item['pos']}  {item['cn_meaning']}")
        doc.add_paragraph(f"å¸¸è§æ­é…ï¼š{item['collocation']}")
        doc.add_paragraph(f"ä¾‹å¥ï¼š{item['example']}")
        doc.add_paragraph(f"è¯å½¢å˜åŒ–ï¼š{item['derivatives']}")
        doc.add_paragraph(f"å½¢è¿‘è¯è¾¨æï¼š{item['confusing']}")
        doc.add_paragraph("")
    buffer = io.BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    st.download_button("ğŸ“„ ä¸‹è½½ Word æ–‡æ¡£", buffer, file_name="è¯æ±‡æ‰©å±•ç»“æœ.docx")
else:
    st.warning("æœªèƒ½è¯†åˆ«åˆ°è¯æ±‡ï¼Œè¯·ç¡®è®¤æˆªå›¾ä¸­æ˜¯å¦åŒ…å«è‹±æ–‡å•è¯å’Œé‡Šä¹‰ã€‚")
